# Implementation of MI-MAML for Few-Shot Malware Classification

![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=flat&logo=PyTorch&logoColor=white)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

This repository contains a from-scratch PyTorch implementation of the research paper:

## **_Mi-maml: classifying few-shot advanced malware using multi-improved model-agnostic meta-learning_**

The project successfully replicates the paper's methodology for classifying malware families from their visual representations using only a few samples.

## Overview

The core challenge addressed by this work is **few-shot malware classification**. Traditional deep learning models require vast amounts of labeled data, which is often unavailable for new and advanced malware families.This project implements the **Model-Agnostic Meta-Learning (MAML)** framework, which trains a model to be highly adaptable, enabling it to learn to classify new, unseen malware families from just a handful of examples (K-shots).

## Key Features & Contributions of This Implementation


This project is not just a direct replication but also includes a novel approach to data augmentation, making it a valuable resource for both researchers and practitioners.

<p align="center">
  <img src="https://github.com/user-attachments/assets/9229ac4f-c53e-4d32-b539-373a44f50e96" width="450" />
  <br>
  <em>Figure 1: Illustration of non-functional code insertion at the image level, implemented with the proposed <code>CodeInserter</code> approach.</em>
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/a661b4ea-8675-44ec-acd1-400ab6cc0958" width="450" />
  <br>
  <em>Figure 2: Illustration of code duplication at the image level, implemented with the proposed <code>CodeDuplicator</code> approach.</em>
</p>


* **Faithful MAML Implementation**: A complete, from-scratch implementation of the First-Order MAML (FOMAML) algorithm, including a custom `TaskSampler` for generating meta-batches and a fully debugged meta-update training loop.

* **Novel Augmentation Simulation**: The original paper proposes data augmentations performed on malware *binaries*. This implementation creatively **translates these domain-specific augmentations to the image domain**, a common real-world scenario where only malware images are available.
    * **Code Insertion**: A `CodeInserter` class simulates the insertion of non-functional code by intelligently "cutting" the flattened image array, inserting a slice of structured noise, and resizing the result.

    * **Code Duplication**: A `CodeDuplicator` class simulates the duplication of code blocks by copying a random patch of the image and pasting it to a new location.

* **Modular & Reusable Code**: The entire pipeline is built with clean, encapsulated classes (`MCCNN`, `TaskSampler`, `LearningRateManager`, and the augmenters), making it easy to understand, modify, and extend.

* **Integrated Experiment Tracking**: The training pipeline is fully integrated with **MLflow**, allowing for systematic tracking of hyperparameters, metrics, and model artifacts for reproducible research.

## Methodology

The pipeline follows the overall architecture proposed in the paper. An input malware image is processed through a custom CNN, which is trained via the MAML algorithm to learn a generalizable initialization.

<p align="center">
  <img src="https://github.com/user-attachments/assets/e24c5996-b81f-464d-8f6d-33dc162d411a" width="572" />
  <br>
  <em>Figure 3: Overall architecture (diagram adapted from Figure 3 in Ji et al.).</em>
</p>


#### **1. Data Augmentation**

Two primary augmentation techniques are used to create a 3-channel input tensor from a single grayscale image:
1.  **The Original Image**: Serves as the first channel.
2.  **Insertion Image**: A new image generated by the `CodeInserter`.
3.  **Duplication Image**: A new image generated by the `CodeDuplicator`.

<p align="center">
  <img src="https://github.com/user-attachments/assets/23c0a3ef-dbbd-4c90-bfe3-2e70b1367ead" width="265" />
  <br>
  <em>Figure 4: Data augmentation method 1 (diagram adapted from Figure 7 in Ji et al.).</em>
</p>


#### **2. Model Architecture**

The project uses the `MCCNN` architecture specified in the paper, consisting of four convolutional blocks with ELU activation and dropout layers .

<p align="center">
  <img src="https://github.com/user-attachments/assets/58e3b9b9-2d79-4188-9384-7e0213c7d943" width="267" />
  <br>
  <em>Figure 5: MC-CNN overall structure (diagram adapted from Figure 7 in Ji et al.).</em>
</p>


## Setup and Installation

1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/your-username/your-repo-name.git](https://github.com/your-username/your-repo-name.git)
    cd your-repo-name
    ```

2.  **Install dependencies:**
    It is recommended to use a virtual environment.
    ```bash
    pip install -r requirements.txt
    ```

    **`requirements.txt`:**
    ```
    torch
    torchvision
    numpy
    Pillow
    tqdm
    mlflow
    matplotlib
    ```

## How to Run

1.  **Data Preparation**:
    Place your resized (e.g., 64x64) malware images in a directory structure organized by family:
    ```
    malimg_resized/
    ├── FamilyA/
    │   ├── 0.png
    │   └── 1.png
    └── FamilyB/
        ├── 0.png
        └── 1.png
    ```

2.  **Configuration**:
    Open the main training script (`train.py`) and configure your experiment in the `Hyperparameters` dataclass. This is where you define your train/val/test family split and set key parameters like `n_way`, `k_shot`, and learning rates.

3.  **Run Training**:
    Execute the main training script from your terminal.
  

4.  **Track with MLflow**:
    While training is running (or after it's done), launch the MLflow UI to view your experiments.
    ```bash
    mlflow ui
    ```
    Then, navigate to `http://127.0.0.1:5000` in your web browser.

## Sample Results




| Configuration   | Best Val Acc | Final Test Acc |
| --------------- | ------------ | -------------- |
| 2-way, 5-shot   | 97.30%       | TBD            |
| 5-way, 5-shot   | TBD          | TBD            |

## Citation

If you use this work, please consider citing the original paper:

```bibtex
@article{ji2024mimaml,
  title={Mi-maml: classifying few-shot advanced malware using multi-improved model-agnostic meta-learning},
  author={Ji, Yulong and Zou, Kunjin and Zou, Bin},
  journal={Cybersecurity},
  volume={7},
  number={1},
  pages={1--19},
  year={2024},
  publisher={Springer}
}

## License
This project is licensed under the MIT License. See the `LICENSE` file for details.
